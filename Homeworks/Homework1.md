---
title: "Information Theory - Homework 1"
geometry: margin=2.5cm
---

1. A fair coin is flipped until the first *head* occurs. Let $X$ denote
the number of flips required until the first *head* occurs.
    a. Find the distribution of X (Note: it has an infinite number of terms).
    b. Compute the entropy H(X). You can use the following relation:
$$\sum_{i=0}^{\infty} n q^n = \frac{q}{(1-q)^2}$$
    c. What is the best way to ask a series of yes-no questions in order to 
find the precise value of $X$? Explain.

\ 

2. A source with memory has the graph depicted below. 
    a. Find the probabilities on all the transitions. Justify.
    b. If the source is initially in state $S_2$, in what state will the source be
after two messages? What is the most likely and the least likely state to be in?
    c. Compute the entropy of the source.

![Graph of the source](img/MemorySource1.pdf){width=30%}


